{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import glob as gb\n",
    "\n",
    "from eppy import modeleditor\n",
    "from eppy.modeleditor import IDF\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import multiprocess as mp\n",
    "\n",
    "import shlex\n",
    "import subprocess\n",
    "from itertools import product\n",
    "\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b33c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN_DIR = '.'\n",
    "IDF_DIR = Path('./files/EnergyPlus/copies').absolute()\n",
    "OUT_DIR_EPlus = Path('./outputs/energyplus').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.glob('**/*.sql', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "igu_low_perf = ['dg_init_bronze', 'dg_0_clear', 'sg_1_clear', 'sg_2_coated']\n",
    "igu_high_perf = ['dg_1_highSHG_highLT', 'dg_2_midSHG_midLT',\n",
    "                 'dg_3_midSHG_highLT', 'dg_4_lowSHG_lowLT',\n",
    "                 'dg_5_lowSHG_midLT', 'dg_6_lowSHG_highLT',\n",
    "                 'dg_5k_Krypton_lowSHG_midLT', 'dg_vacuum',\n",
    "                 'tg_1_highSHG_highLT', 'tg_2_midSHG_midLT',\n",
    "                 'tg_3_midSHG_highLT', 'tg_4_lowSHG_lowLT',\n",
    "                 'tg_5_lowSHG_midLT', 'tg_6_lowSHG_highLT',\n",
    "                 'tg_5k_Krypton_lowSHG_midLT', 'tg_5x_Xenon_lowSHG_midLT',\n",
    "                 'ccf'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a46ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_conditioned_area = 8100\n",
    "glazed_facade_area = 2750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79971652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EPLusSQL():\n",
    "\n",
    "    def __init__(self, sql_path=None):\n",
    "        abs_sql_path = os.path.abspath(sql_path)\n",
    "        self.sql_uri = '{}?mode=ro'.format(pathlib.Path(abs_sql_path).as_uri())\n",
    "\n",
    "    def get_annual_energy_by_fuel_and_enduse(self):\n",
    "        \"\"\"\n",
    "        Queries SQL file and returns the ABUPS' End Uses table\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df_end_use: pd.DataFrame\n",
    "            Annual End Use table\n",
    "            index = 'EndUse'\n",
    "            columns = ['FuelType','Units']\n",
    "        \"\"\"\n",
    "\n",
    "        # RowName = '#{end_use}'\n",
    "        # ColumnName='#{fuel_type}'\n",
    "        annual_end_use_query = \"\"\"SELECT RowName, ColumnName, Units, Value\n",
    "            FROM TabularDataWithStrings\n",
    "            WHERE ReportName='AnnualBuildingUtilityPerformanceSummary'\n",
    "            AND ReportForString='Entire Facility'\n",
    "            AND TableName='End Uses'\n",
    "        \"\"\"\n",
    "\n",
    "        with sqlite3.connect(self.sql_uri, uri=True) as con:\n",
    "            df_end_use = pd.read_sql(annual_end_use_query, con=con)\n",
    "\n",
    "        # Convert Value to Float\n",
    "        df_end_use['Value'] = pd.to_numeric(df_end_use['Value'])\n",
    "\n",
    "        df_end_use = df_end_use.set_index(['RowName',\n",
    "                                           'ColumnName',\n",
    "                                           'Units'])['Value'].unstack([1, 2])\n",
    "        df_end_use.index.name = 'EndUse'\n",
    "        df_end_use.columns.names = ['FuelType', 'Units']\n",
    "\n",
    "        end_use_order = ['Heating', 'Cooling',\n",
    "                         'Interior Lighting', 'Exterior Lighting',\n",
    "                         'Interior Equipment', 'Exterior Equipment',\n",
    "                         'Fans', 'Pumps', 'Heat Rejection', 'Humidification',\n",
    "                         'Heat Recovery', 'Water Systems',\n",
    "                         'Refrigeration', 'Generators']\n",
    "        col_order = [\n",
    "            'Electricity', 'Natural Gas', 'Gasoline', 'Diesel', 'Coal',\n",
    "            'Fuel Oil No 1', 'Fuel Oil No 2', 'Propane', 'Other Fuel 1',\n",
    "            'Other Fuel 2', 'District Cooling', 'District Heating',\n",
    "            'Water']\n",
    "        df_end_use = df_end_use[col_order].loc[end_use_order]\n",
    "\n",
    "        # Filter out columns with ALL zeroes\n",
    "        df_end_use = df_end_use.loc[:, (df_end_use > 0).any(axis=0)]\n",
    "\n",
    "        return df_end_use\n",
    "\n",
    "    def get_unmet_hours_table(self):\n",
    "        \"\"\"\n",
    "        Queries 'SystemSummary' and returns all unmet hours\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df_unmet: pd.DataFrame\n",
    "            A DataFrame where\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        query = \"\"\"SELECT RowName, ColumnName, Units, Value FROM TabularDataWithStrings\n",
    "    WHERE ReportName='SystemSummary'\n",
    "    AND ReportForString='Entire Facility'\n",
    "    AND TableName='Time Setpoint Not Met'\n",
    "    \"\"\"\n",
    "        with sqlite3.connect(self.sql_uri, uri=True) as con:\n",
    "            df_unmet = pd.read_sql(query, con=con)\n",
    "\n",
    "        # Convert Value to Float\n",
    "        df_unmet['Value'] = pd.to_numeric(df_unmet['Value'])\n",
    "\n",
    "        df_unmet = df_unmet.pivot(index='RowName',\n",
    "                                  columns='ColumnName',\n",
    "                                  values='Value')\n",
    "\n",
    "        df_unmet.columns.names = ['Time Setpoint Not Met (hr)']\n",
    "\n",
    "        # Move 'Facility' as last row (Should always be in the index...)\n",
    "        if 'Facility' in df_unmet.index:\n",
    "            df_unmet = df_unmet.loc[[x for x\n",
    "                                     in df_unmet.index\n",
    "                                     if x != 'Facility'] + ['Facility']]\n",
    "\n",
    "        return df_unmet\n",
    "\n",
    "    def get_reporting_vars(self):\n",
    "        \"\"\"\n",
    "        Queries 'ReportingDataDictionary' and returns a DataFrame\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        df_vars: pd.DataFrame\n",
    "            A DataFrame where each row is a reporting variable\n",
    "        \"\"\"\n",
    "\n",
    "        with sqlite3.connect(self.sql_uri, uri=True) as con:\n",
    "            query = '''\n",
    "        SELECT KeyValue, Name, TimestepType, ReportingFrequency, Units, Type\n",
    "            FROM ReportDataDictionary\n",
    "            '''\n",
    "            df_vars = pd.read_sql(query, con=con)\n",
    "\n",
    "        return df_vars\n",
    "\n",
    "    def get_hourly_variables(self, variables_list):\n",
    "        \"\"\"\n",
    "        Queries Hourly variables which names are in variables_list\n",
    "\n",
    "        eg: variables_list=['Zone Thermal Comfort CEN 15251 Adaptive Model Temperature']\n",
    "        \"\"\"\n",
    "\n",
    "        query = '''\n",
    "        SELECT EnvironmentPeriodIndex, Month, Day, Hour, Minute,\n",
    "            ReportingFrequency, KeyValue, Name, Units,\n",
    "            Value\n",
    "        FROM ReportVariableWithTime\n",
    "        '''\n",
    "\n",
    "        cond = []\n",
    "\n",
    "        cond.append(\n",
    "            (\"UPPER(Name) IN ({})\".format(', '.join(\n",
    "                map(repr, [name.upper() for name in variables_list]))))\n",
    "        )\n",
    "\n",
    "        cond.append('ReportingFrequency = \"Hourly\"')\n",
    "\n",
    "        query += '  WHERE {}'.format('\\n    AND '.join(cond))\n",
    "\n",
    "        with sqlite3.connect(self.sql_uri, uri=True) as con:\n",
    "            df = pd.read_sql(query, con=con)\n",
    "\n",
    "        df_pivot = pd.pivot_table(df, values='Value',\n",
    "                                  columns=['ReportingFrequency', 'KeyValue',\n",
    "                                           'Name', 'Units'],\n",
    "                                  index=['EnvironmentPeriodIndex',\n",
    "                                         'Month', 'Day', 'Hour', 'Minute'])\n",
    "\n",
    "        df_pivot = df_pivot.loc[3]  # Get the annual environment period index\n",
    "\n",
    "        # We know it's hourly, so recreate a clear index\n",
    "        (month, day, hour, minute) = df_pivot.index[0]\n",
    "        start = datetime.datetime(2005, month, day)\n",
    "        df_pivot.index = pd.date_range(\n",
    "            start=start, periods=df_pivot.index.size, freq='H')\n",
    "        df_pivot = df_pivot['Hourly']\n",
    "\n",
    "        return df_pivot\n",
    "\n",
    "    def get_timestep_variables(self, variables_list=None):\n",
    "        \"\"\"\n",
    "        Queries 'Zone Timestep' variables which names are in variables_list (if supplied, otherwise all)\n",
    "\n",
    "        eg: variables_list=['Zone Thermal Comfort CEN 15251 Adaptive Model Temperature']\n",
    "        \"\"\"\n",
    "\n",
    "        query = '''\n",
    "        SELECT EnvironmentPeriodIndex, Month, Day, Hour, Minute,\n",
    "            ReportingFrequency, KeyValue, Name, Units,\n",
    "            Value\n",
    "        FROM ReportVariableWithTime\n",
    "        '''\n",
    "\n",
    "        cond = []\n",
    "\n",
    "        if variables_list:\n",
    "            cond.append(\n",
    "                (\"UPPER(Name) IN ({})\".format(', '.join(\n",
    "                    map(repr, [name.upper() for name in variables_list]))))\n",
    "            )\n",
    "\n",
    "        cond.append('ReportingFrequency = \"Zone Timestep\"')\n",
    "\n",
    "        query += '  WHERE {}'.format('\\n    AND '.join(cond))\n",
    "\n",
    "        with sqlite3.connect(self.sql_uri, uri=True) as con:\n",
    "            df = pd.read_sql(query, con=con)\n",
    "\n",
    "        df_pivot = pd.pivot_table(df, values='Value',\n",
    "                                  columns=['ReportingFrequency', 'KeyValue',\n",
    "                                           'Name', 'Units'],\n",
    "                                  index=['EnvironmentPeriodIndex',\n",
    "                                         'Month', 'Day', 'Hour', 'Minute'])\n",
    "\n",
    "        df_pivot = df_pivot.loc[3]  # Get the annual environment period index\n",
    "\n",
    "        # We know it's Zone Timestep, with 15min timestep, so recreate a clear index\n",
    "        (month, day, hour, minute) = df_pivot.index[0]\n",
    "        start = datetime.datetime(2005, month, day)\n",
    "\n",
    "        df_pivot.index = pd.date_range(\n",
    "            start=start, periods=df_pivot.index.size, freq='15Min')\n",
    "        df_pivot = df_pivot['Zone Timestep']\n",
    "\n",
    "        return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_idf(idfname_init, epwfile, igu, run_n, df_step):\n",
    "    \"\"\"\n",
    "    Modify the idf parameters, i.e. glazing, frame, and shadings, \n",
    "    according to the parameters defined in the dataframe,\n",
    "    and returns the idf file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    idfname_init: idf file to modify\n",
    "    epwfile: weather data, .epw\n",
    "    igu: name of the igu studied for energy simulation\n",
    "    run_n: name/code for the energy simulation\n",
    "    df_step: dataframe w/ a list of variables according to which are changed\n",
    "        the idf parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    idf_modified: a copy (saved as) of the initial idf\n",
    "    \"\"\"\n",
    "\n",
    "    idf = IDF(idfname_init, epwfile)\n",
    "    constructions = idf.idfobjects[\"CONSTRUCTION\"]\n",
    "\n",
    "    # Change the glazing and frame:\n",
    "    for element in idf.idfobjects['FenestrationSurface:Detailed']:\n",
    "        if element.Surface_Type == 'Window':\n",
    "\n",
    "            # Replace the glazing:\n",
    "            element.Construction_Name = igu\n",
    "            if igu not in [\n",
    "                construction.Name for construction in constructions\n",
    "            ]:\n",
    "                print('Wrong construction name!! See:', igu)\n",
    "\n",
    "    # Replace the frame:\n",
    "    for element in idf.idfobjects['WindowProperty:FrameAndDivider']:\n",
    "        if igu in igu_low_perf:\n",
    "            # if df_step.loc[df_step.index == run_n, 'thermal_curtain'][0] == 0:\n",
    "            # element.Frame_Conductance = 5.5\n",
    "            # element.Divider_Conductance = 5.5\n",
    "            # else:\n",
    "            element.Frame_Conductance = 1.56\n",
    "            element.Divider_Conductance = 1.56\n",
    "\n",
    "        if igu in igu_high_perf:\n",
    "            # if df_step.loc[df_step.index == run_n, 'thermal_curtain'][0] == 0:\n",
    "            # element.Frame_Conductance = 1.5\n",
    "            # element.Divider_Conductance = 1.5\n",
    "            # else:\n",
    "            element.Frame_Conductance = 1\n",
    "            element.Divider_Conductance = 1\n",
    "\n",
    "    # Activate or not the shading control:\n",
    "    for element in idf.idfobjects['WindowShadingControl']:\n",
    "        element.Shading_Device_Material_Name = 'EnviroScreen_lightgrey_silver'\n",
    "        element.Shading_Control_Type = 'OnIfHighZoneAirTempAndHighSolarOnWindow'\n",
    "        element.Schedule_Name = 'Shading_On'\n",
    "        element.Shading_Control_Is_Scheduled = 'Yes'\n",
    "        element.Glare_Control_Is_Active = 'No'\n",
    "        element.Type_of_Slat_Angle_Control_for_Blinds = 'FixedSlatAngle'\n",
    "\n",
    "        if df_step.loc[df_step.index == run_n, 'int_shdg_device'][0] == 1:\n",
    "            element.Setpoint = '26'\n",
    "            element.Setpoint_2 = '100'\n",
    "            element.Shading_Type = 'InteriorShade'\n",
    "\n",
    "        elif df_step.loc[df_step.index == run_n, 'ext_shdg_device'][0] == 1:\n",
    "            element.Setpoint = '22'\n",
    "            element.Setpoint_2 = '100'\n",
    "            element.Shading_Type = 'InteriorShade'\n",
    "            element.Shading_Type = 'ExteriorShade'\n",
    "\n",
    "        else:\n",
    "            element.Schedule_Name = 'Shading_OFF'\n",
    "\n",
    "    # Define heating and cooling setpoint:\n",
    "    for element in idf.idfobjects['ThermostatSetpoint:DualSetpoint']:\n",
    "        if ('Core' in element.Name\n",
    "                or 'Perimeter' in element.Name):\n",
    "            element.Heating_Setpoint_Temperature_Schedule_Name = (\n",
    "                df_step.loc[df_step.index == run_n, 'heating_setpoint'][0])\n",
    "            element.Cooling_Setpoint_Temperature_Schedule_Name = (\n",
    "                df_step.loc[df_step.index == run_n, 'cooling_setpoint'][0])\n",
    "    \n",
    "    # Subdirectory with idf:    \n",
    "    idf_dir = os.path.join(IDF_DIR)\n",
    "\n",
    "    idf.saveas(idf_dir+\"\\BEM_\"+str(run_n)+\".idf\")\n",
    "    idf_modified = IDF(idf_dir+\"\\BEM_\"+str(run_n)+\".idf\", epwfile)\n",
    "\n",
    "    print(\"Saved: BEM_\"+str(run_n))\n",
    "\n",
    "    return idf_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b831830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_postprocess(run_n, path, \n",
    "                           ls_df_steps, ls_unmet, df_end_use_allsteps):\n",
    "    \"\"\"\n",
    "    Run a simulation from an idf, extract results in df or ls:\n",
    "    > total energy end use in df_end_use (electricity + natural gas)\n",
    "    > unmethours during occupation in ls_unmet\n",
    "    > Energy consumption per enduse in df_end_use_allsteps\n",
    "\n",
    "    Save also the hourly reporting variables per simulation run \n",
    "    in a csv file: df_h_run.csv.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    run_n: name/code for the energy simulation\n",
    "    df_step: df define for each step of the LCA where to save\n",
    "        values for electricity and natural gas use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_step: electricity use in kWh, use of nat gas in MJ\n",
    "    ls_unmet\n",
    "    df_end_use_allsteps: values in GJ\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    for df in ls_df_steps:\n",
    "        if run_n in df.index:\n",
    "            df_step = df\n",
    "    \n",
    "    # Find the output data:\n",
    "    eplus_sql = EPLusSQL(sql_path=path+'\\eplusout.sql')\n",
    "\n",
    "    # Get total(i.e. whole building) energy end use in a dataframe, in GJ:\n",
    "    df_end_use = eplus_sql.get_annual_energy_by_fuel_and_enduse()\n",
    "    if 'Water' in df_end_use.columns:\n",
    "        df_end_use = df_end_use.drop('Water', axis=1)\n",
    "    df_end_use = df_end_use.drop([\n",
    "        'Exterior Lighting', 'Exterior Equipment', 'Generators',\n",
    "        'Water Systems', 'Heat Recovery', 'Humidification', 'Refrigeration'])\n",
    "\n",
    "    # Save total elec and nat gas use for LCA in df_step:\n",
    "    # Sum of the electricity uses:\n",
    "    elec_tot_gj = df_end_use[('Electricity', 'GJ')].sum()\n",
    "    # Convert GJ to kWh:\n",
    "    elec_tot_kwh = elec_tot_gj * 277.8\n",
    "\n",
    "    # Use of natural gas:\n",
    "    if 'Natural Gas' not in df_end_use.columns:\n",
    "        df_end_use[('Natural Gas', 'GJ')] = 0\n",
    "\n",
    "    # Use of natural gas:\n",
    "    gas_tot_gj = df_end_use[('Natural Gas', 'GJ')].sum()\n",
    "    # Convert GJ to MJ:\n",
    "    gas_tot_mj = gas_tot_gj * 1000\n",
    "    \n",
    "    # Save values in df_step:\n",
    "    # elec: kWh/m² of glazed façade\n",
    "    df_step.loc[df_step.index == run_n, 'elec_use'] = (\n",
    "        elec_tot_kwh / glazed_facade_area)\n",
    "    # gas: MJ/m² of glazed façade\n",
    "    df_step.loc[df_step.index == run_n, 'natural_gas'] = (\n",
    "        gas_tot_mj / glazed_facade_area)\n",
    "\n",
    "    # Append the list of unmet hours during occupied cooling/heating:\n",
    "    df_unmet = eplus_sql.get_unmet_hours_table()\n",
    "    val_toadd = {'Run': run_n,\n",
    "                 'During cooling': df_unmet.loc[df_unmet.index == 'Facility',\n",
    "                                                'During Occupied Cooling'][0],\n",
    "                 'During heating': df_unmet.loc[df_unmet.index == 'Facility',\n",
    "                                                'During Occupied Heating'][0]\n",
    "                 }\n",
    "    \n",
    "    # Avoid duplicating values:\n",
    "    if len(ls_unmet) > 0:\n",
    "        for i in range(len(ls_unmet)):\n",
    "            if ls_unmet[i]['Run'] == val_toadd['Run']:\n",
    "                # Replace old value:\n",
    "                ls_unmet[i] = val_toadd\n",
    "    else:\n",
    "        # And append if did not exist before:\n",
    "        ls_unmet.append(val_toadd)\n",
    "\n",
    "    # Save energy consumption per end use, GJ, whole building:\n",
    "    df_end_use = df_end_use.stack(['FuelType'])\n",
    "    df_end_use['Run name'] = run_n\n",
    "    df_end_use = df_end_use.reset_index().pivot(\n",
    "        index='EndUse', columns=['Run name', 'FuelType'], values='GJ')\n",
    "    \n",
    "    if not df_end_use_allsteps.empty:\n",
    "        # Columns to avoid when merging, avoid duplicates and save new values:\n",
    "        cols_to_use = df_end_use_allsteps.columns.difference(\n",
    "            df_end_use.columns)\n",
    "        # Merge by columns_to_use:\n",
    "        df_end_use_allsteps = pd.merge(df_end_use,\n",
    "                                       df_end_use_allsteps[cols_to_use],\n",
    "                                       on=\"EndUse\")\n",
    "    else:\n",
    "        df_end_use_allsteps = df_end_use\n",
    "\n",
    "    df_end_use_allsteps = df_end_use_allsteps.reindex(\n",
    "        sorted(df_end_use_allsteps.columns), axis=1\n",
    "    )\n",
    "\n",
    "    # Hourly reporting variables\n",
    "    # Define an empty DataFrame to save the hourly reporting variables:\n",
    "    df_h_run = pd.DataFrame()\n",
    "\n",
    "    ls_vars = [\n",
    "        'Zone Windows Total Heat Gain Energy',\n",
    "        'Zone Windows Total Heat Loss Energy',\n",
    "        'Surface Shading Device Is On Time Fraction',\n",
    "        'Zone Operative Temperature',\n",
    "        'Zone Thermal Comfort CEN 15251 Adaptive Model Temperature',\n",
    "        'Zone Thermal Comfort ASHRAE 55 Adaptive Model Temperature',\n",
    "        'Chiller Electricity Energy', 'Boiler Heating Energy'\n",
    "    ]\n",
    "\n",
    "    df_h_run = eplus_sql.get_hourly_variables(variables_list=ls_vars)\n",
    "\n",
    "    for col in df_h_run.columns:\n",
    "        if \"BASEMENT\" in col[0]:\n",
    "            df_h_run = df_h_run.drop(col, axis=1)\n",
    "\n",
    "    # Save df_h_run to csv:\n",
    "    df_h_run.to_csv('outputs\\steps_dir\\df_h_run_'+str(run_n[:3])+'.csv',\n",
    "                    index=True)\n",
    "\n",
    "    return run_n, df_step, ls_unmet, df_end_use_allsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd512abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_csv(run_n, df_step, ls_unmet, df_end_use_allsteps):\n",
    "    \"\"\"\n",
    "    Save the DataFrames and Lists where the results are to avoid \n",
    "    reruning the time consuming energy simulation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    run_n: simulation\n",
    "    df_step: df define for each step of the LCA where to save\n",
    "        values for electricity and natural gas use.\n",
    "    ls_unmet: list for unmet hours during occupation\n",
    "    df_end_use_allsteps: dataframe with end uses \n",
    "        per type of energy per simulation run\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    n = [ord(run_n[0]) - 96]\n",
    "\n",
    "    # Save df_step to csv:\n",
    "    df_step.to_csv('outputs\\steps_dir\\df_step'+str(n[0])+'.csv', index=True)\n",
    "    \n",
    "    # Save ls_unmet to csv:\n",
    "    df_ls_unmet = pd.DataFrame(ls_unmet)\n",
    "    df_ls_unmet.to_csv('outputs\\steps_dir\\df_ls_unmet.csv', index=False)\n",
    "    \n",
    "    # Save df_end_use_allsteps to csv:\n",
    "    df_end_use_allsteps.stack([0, 1]).to_csv(\n",
    "        'outputs\\steps_dir\\df_end_use_allsteps.csv', index=True)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_simulation(args):\n",
    "    \"\"\"\n",
    "    Gets a tuple of arguments, \n",
    "        eg: (file1.idf, weather.epw, run_n)\n",
    "    \"\"\"\n",
    "    idf_path = os.path.relpath(args[0], ORIGIN_DIR)\n",
    "    epw_path = os.path.relpath(args[1], ORIGIN_DIR)\n",
    "\n",
    "    idf, idf_ext = os.path.splitext(idf_path)\n",
    "    epw, epw_ext = os.path.splitext(epw_path)\n",
    "    \n",
    "    out_dir = os.path.relpath(os.path.join(OUT_DIR_EPlus, args[2]), ORIGIN_DIR)\n",
    "\n",
    "    cmd = f'energyplus -w {epw_path} -d {out_dir} {idf_path}'\n",
    "    res = subprocess.run(cmd, capture_output=True)\n",
    "    \n",
    "    if res.returncode != 0:\n",
    "        print(\"Simulation failed for {idf_path} / {epw_path}\")\n",
    "        print(res.stdout.decode())\n",
    "        print(res.stderr.decode())\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    return args[2], out_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
